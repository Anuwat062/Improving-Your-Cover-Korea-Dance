{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ffpyplayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import datetime\n",
    "import statistics as stat\n",
    "from ffpyplayer.player import MediaPlayer\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(first,mid,end):\n",
    "    a = np.array(first) # First\n",
    "    b = np.array(mid) # Mid\n",
    "    c = np.array(end) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosinesim(source, test):\n",
    "    \n",
    "    a = np.matmul(np.transpose(source), test)\n",
    "    b = np.sum(np.multiply(source, source))\n",
    "    c = np.sum(np.multiply(test, test))\n",
    "    \n",
    "    return (a / (np.sqrt(b)*np.sqrt(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_angle([1,1],[2,2],[3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/3j8BPdc.png\" style=\"height:300px\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final = cv2.imread(\"./final_backgroup.jpg\")\n",
    "\n",
    "# final1 = final.copy()\n",
    "# final_frame = cv2.resize(final1, (768,864))\n",
    "#   final_frame = cv2.resize(final, (frame2.shape[0], frame2.shape[1]))\n",
    "# cv2.imshow(\"Compare\", final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve Your Korea (K-pop Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bgv = cv2.VideoCapture(\"./lisa1.mp4\")\n",
    "hmv = cv2.VideoCapture(\"./lisa2.mp4\")\n",
    "# bgv = cv2.VideoCapture(\"./2_green_dancing.mp4\")\n",
    "# hmv = cv2.VideoCapture(\"./2_green_dancing.mp4\")\n",
    "# hmv = cv2.VideoCapture(\"./Image video project/2.mp4\")\n",
    "# bgv = cv2.VideoCapture(\"./Image video project/3.mp4\")\n",
    "# final = cv2.imread(\"./Image video project/final_backgroup.jpg\")\n",
    "x = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "# video_path= \"./lisa2.mp4\"  \n",
    "\n",
    "compare_collection = []\n",
    "compare_collection_sim = []\n",
    "\n",
    "s_nose1 = []\n",
    "s_elbow_L1 = []\n",
    "s_elbow_R1 = []\n",
    "s_shoulder_L1 = []\n",
    "s_shoulder_R1 = []\n",
    "s_hip_L1 = []\n",
    "s_hip_R1 = []\n",
    "s_knee_L1 = []\n",
    "s_knee_R1 = []\n",
    "\n",
    "diff_n_all = []\n",
    "diff_e_L_all = []\n",
    "diff_e_R_all = []\n",
    "diff_s_L_all = []\n",
    "diff_s_R_all = []\n",
    "diff_h_L_all = []\n",
    "diff_h_R_all = []   \n",
    "diff_k_L_all = []\n",
    "diff_k_R_all = []\n",
    "\n",
    "list_percent = []\n",
    "\n",
    "n = 1\n",
    "\n",
    "frame_array = []\n",
    "\n",
    "# if bgv.isOpened() and hmv.isOpened():\n",
    "#     print('Video file opened successfully.')\n",
    "# else:\n",
    "#     print('Error. Video file could not be opened.')\n",
    "\n",
    "# frames per second ==> lower it to slow down the video\n",
    "# fps = 1000\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "# to select mode (record or not)\n",
    "mode = input(\"Do you want to record the result as a video? (Y/N): \").upper()\n",
    "\n",
    "while mode not in ('Y', 'N'):\n",
    "    \n",
    "    print('Wrong input!')\n",
    "    mode = input(\"Do you want to record the result as a video? (Y/N): \").upper()\n",
    "\n",
    "# player = MediaPlayer(video_path)\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        ret1, bg1 = bgv.read()\n",
    "        ret2, hm2 = hmv.read()\n",
    "#         audio_frame, val = player.get_frame()\n",
    "        \n",
    "        prevTime = time.time()\n",
    "        rt = 0.7\n",
    "        \n",
    "        if bg1 is None:\n",
    "#             768 ,432\n",
    "\n",
    "            break \n",
    "#     img1 = cv2.imread(\"./nida_background.jpg\")\n",
    "#     img = img1.copy()\n",
    "#     img = cv2.resize(img,(w,h))\n",
    "# cv2.rectangle(image1, (0,0), (265,63), (245,117,16), -1)\n",
    "\n",
    "#             # Rep data\n",
    "# cv2.putText(image1, 'CUMULATIVE SIMILARITY', (10,15), \n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "# y = datetime.datetime.now().replace(microsecond=0)\n",
    "# z = y-x\n",
    "# #           print(z)\n",
    "\n",
    "#             # Stage data\n",
    "# cv2.putText(image1, 'SCORE', (200,15), \n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            \n",
    "        whm = int(bg1.shape[1] *rt*1.1)\n",
    "        hhm = int(hm2.shape[0] *rt*1)\n",
    "    \n",
    "        frame1 = cv2.resize(bg1, (whm, hhm))\n",
    "        frame2 = cv2.resize(hm2, (whm, hhm))\n",
    "\n",
    "        # Recolor image to RGB\n",
    "        image1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "        image2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
    "        image1.flags.writeable = False\n",
    "        image2.flags.writeable = False\n",
    "\n",
    "        # Make detection\n",
    "        results1 = pose.process(image1)\n",
    "        results2 = pose.process(image2)\n",
    "\n",
    "        # Recolor back to BGR\n",
    "        image1.flags.writeable = True\n",
    "        image2.flags.writeable = True\n",
    "        image1 = cv2.cvtColor(image1, cv2.COLOR_RGB2BGR)\n",
    "        image2 = cv2.cvtColor(image2, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "        worst_position = 0\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks1 = results1.pose_world_landmarks.landmark\n",
    "            landmarks1_ = results1.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            nose1 = [landmarks1[mp_pose.PoseLandmark.NOSE.value].x,landmarks1[mp_pose.PoseLandmark.NOSE.value].y]\n",
    "            wrist_L1 = [landmarks1[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks1[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            wrist_R1 = [landmarks1[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks1[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            elbow_L1 = [landmarks1[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks1[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            elbow_R1 = [landmarks1[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks1[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            shoulder_L1 = [landmarks1[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks1[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            shoulder_R1 = [landmarks1[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks1[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            hip_L1 = [landmarks1[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks1[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            hip_R1 = [landmarks1[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks1[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            knee_L1 = [landmarks1[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks1[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            knee_R1 = [landmarks1[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks1[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            ankle_L1 = [landmarks1[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks1[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            ankle_R1 = [landmarks1[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks1[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]   \n",
    "\n",
    "\n",
    "            # Calculate angle\n",
    "            angle_nose1 = round(calculate_angle(shoulder_L1, nose1, shoulder_R1),2)\n",
    "            angle_elbow_L1 = round(calculate_angle(shoulder_L1, elbow_L1, wrist_L1),2)\n",
    "            angle_elbow_R1 = round(calculate_angle(shoulder_R1, elbow_R1, wrist_R1),2)\n",
    "            angle_shoulder_L1 = round(calculate_angle(elbow_L1, shoulder_L1, hip_L1),2)\n",
    "            angle_shoulder_R1 = round(calculate_angle(elbow_R1, shoulder_R1, hip_R1),2)\n",
    "            angle_hip_L1 = round(calculate_angle(shoulder_L1, hip_L1, knee_L1),2)\n",
    "            angle_hip_R1 = round(calculate_angle(shoulder_R1, hip_R1, knee_R1),2)            \n",
    "            angle_knee_L1 = round(calculate_angle(ankle_L1, knee_L1, hip_L1),2)\n",
    "            angle_knee_R1 = round(calculate_angle(ankle_R1, knee_R1, hip_R1),2)                       \n",
    "            \n",
    "            s_nose1.append(angle_nose1)\n",
    "            s_elbow_L1.append(angle_elbow_L1)\n",
    "            s_elbow_R1.append(angle_elbow_R1)\n",
    "            s_shoulder_L1.append(angle_shoulder_L1)\n",
    "            s_shoulder_R1.append(angle_shoulder_R1)\n",
    "            s_hip_L1.append(angle_hip_L1)\n",
    "            s_hip_R1.append(angle_hip_R1)\n",
    "            s_knee_L1.append(angle_knee_L1)\n",
    "            s_knee_R1.append(angle_knee_R1)      \n",
    "\n",
    "            landmarks2 = results2.pose_world_landmarks.landmark            \n",
    "            landmarks2_ = results2.pose_landmarks.landmark\n",
    "           \n",
    "            # Get coordinates\n",
    "            nose2 = [landmarks2[mp_pose.PoseLandmark.NOSE.value].x,landmarks2[mp_pose.PoseLandmark.NOSE.value].y]\n",
    "            wrist_L2 = [landmarks2[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks2[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            wrist_R2 = [landmarks2[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks2[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            elbow_L2 = [landmarks2[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks2[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            elbow_R2 = [landmarks2[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks2[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            shoulder_L2 = [landmarks2[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks2[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            shoulder_R2 = [landmarks2[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks2[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            hip_L2 = [landmarks2[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks2[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            hip_R2 = [landmarks2[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks2[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            knee_L2 = [landmarks2[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks2[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            knee_R2 = [landmarks2[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks2[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            ankle_L2 = [landmarks2[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks2[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            ankle_R2 = [landmarks2[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks2[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            \n",
    "            # Calculate angle\n",
    "            angle_nose2 = round(calculate_angle(shoulder_L2, nose2, shoulder_R2),2)\n",
    "            angle_elbow_L2 = round(calculate_angle(shoulder_L2, elbow_L2, wrist_L2),2)\n",
    "            angle_elbow_R2 = round(calculate_angle(shoulder_R2, elbow_R2, wrist_R2),2)\n",
    "            angle_shoulder_L2 = round(calculate_angle(elbow_L2, shoulder_L2, hip_L2),2)\n",
    "            angle_shoulder_R2 = round(calculate_angle(elbow_R2, shoulder_R2, hip_R2),2)\n",
    "            angle_hip_L2 = round(calculate_angle(shoulder_L2, hip_L2, knee_L2),2)\n",
    "            angle_hip_R2 = round(calculate_angle(shoulder_R2, hip_R2, knee_R2),2) \n",
    "            angle_knee_L2 = round(calculate_angle(ankle_L2, knee_L2, hip_L2),2)\n",
    "            angle_knee_R2 = round(calculate_angle(ankle_R2, knee_R2, hip_R2),2)\n",
    "            \n",
    "            compare_nose = abs(round(angle_nose2-angle_nose1,2))\n",
    "            compare_elbow_L = abs(round(angle_elbow_L2-angle_elbow_L1,2))\n",
    "            compare_elbow_R = abs(round(angle_elbow_R2-angle_elbow_R1,2))\n",
    "            compare_shoulder_L = abs(round(angle_shoulder_L2-angle_shoulder_L1,2)) \n",
    "            compare_shoulder_R = abs(round(angle_shoulder_R2-angle_shoulder_R1,2))            \n",
    "            compare_hip_L = abs(round(angle_hip_L2-angle_hip_L1,2)) \n",
    "            compare_hip_R = abs(round(angle_hip_R2-angle_hip_R1,2))\n",
    "            compare_knee_L = abs(round(angle_knee_L2-angle_knee_L1,2)) \n",
    "            compare_knee_R = abs(round(angle_knee_R2-angle_knee_R1,2)) \n",
    "            \n",
    "            compare_collection.append(compare_nose)\n",
    "            compare_collection.append(compare_elbow_L)\n",
    "            compare_collection.append(compare_elbow_R)    \n",
    "            compare_collection.append(compare_shoulder_L)\n",
    "            compare_collection.append(compare_shoulder_R)\n",
    "            compare_collection.append(compare_hip_L)\n",
    "            compare_collection.append(compare_hip_R)\n",
    "            compare_collection.append(compare_knee_L)\n",
    "            compare_collection.append(compare_knee_R)\n",
    "            \n",
    "            compare_score = sum(compare_collection)/len(compare_collection)\n",
    "            \n",
    "            # Calculate CosineSimilarity\n",
    "            cosinesim_nose = calculate_cosinesim(nose1,nose2)\n",
    "            cosinesim_elbow_L = calculate_cosinesim(elbow_L1,elbow_L2)\n",
    "            cosinesim_elbow_R = calculate_cosinesim(elbow_R1,elbow_R2)\n",
    "            cosinesim_shoulder_L = calculate_cosinesim(shoulder_L1,shoulder_L2)\n",
    "            cosinesim_shoulder_R = calculate_cosinesim(shoulder_R1,shoulder_R2)            \n",
    "            cosinesim_hip_L = calculate_cosinesim(hip_L1,hip_L2)\n",
    "            cosinesim_hip_R = calculate_cosinesim(hip_R1,hip_R2)\n",
    "            cosinesim_knee_L = calculate_cosinesim(knee_L1,knee_L2)\n",
    "            cosinesim_knee_R = calculate_cosinesim(knee_R1,knee_R2)\n",
    "            \n",
    "            compare_collection_sim.append(cosinesim_nose)\n",
    "            compare_collection_sim.append(cosinesim_elbow_L)\n",
    "            compare_collection_sim.append(cosinesim_elbow_R)    \n",
    "            compare_collection_sim.append(cosinesim_shoulder_L)\n",
    "            compare_collection_sim.append(cosinesim_shoulder_R)\n",
    "            compare_collection_sim.append(cosinesim_hip_L)\n",
    "            compare_collection_sim.append(cosinesim_hip_R)\n",
    "            compare_collection_sim.append(cosinesim_knee_L)\n",
    "            compare_collection_sim.append(cosinesim_knee_R)                       \n",
    "            \n",
    "            compare_score_sim = sum(compare_collection_sim)/len(compare_collection_sim)\n",
    "            \n",
    "            #Diff\n",
    "            diff_n = abs(angle_nose2 - angle_nose1)\n",
    "            diff_e_L = abs(angle_elbow_L2 - angle_elbow_L1)\n",
    "            diff_e_R = abs(angle_elbow_R2 - angle_elbow_R1)\n",
    "            diff_s_L = abs(angle_shoulder_L2 - angle_shoulder_L1)\n",
    "            diff_s_R = abs(angle_shoulder_R2 - angle_shoulder_R1)\n",
    "            diff_h_L = abs(angle_hip_L2 - angle_hip_L1)\n",
    "            diff_h_R = abs(angle_hip_R2 - angle_hip_R1)    \n",
    "            diff_k_L = abs(angle_knee_L2 - angle_knee_L1)\n",
    "            diff_k_R = abs(angle_knee_R2 - angle_knee_R1)\n",
    "         \n",
    "            diff_n_all.append(diff_n)\n",
    "            diff_e_L_all.append(diff_e_L)\n",
    "            diff_e_R_all.append(diff_e_R)\n",
    "            diff_s_L_all.append(diff_s_L)\n",
    "            diff_s_R_all.append(diff_s_R)\n",
    "            diff_h_L_all.append(diff_h_L)\n",
    "            diff_h_R_all.append(diff_h_R)\n",
    "            diff_k_L_all.append(diff_k_L)\n",
    "            diff_k_R_all.append(diff_k_R)\n",
    "\n",
    "            # Visualize angle\n",
    "            cv2.putText(image1, str(angle_nose1), \n",
    "                            tuple(np.multiply(nose1, [100, 480]).astype(int)), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                            )\n",
    "            cv2.putText(image2, str(angle_nose2), \n",
    "                            tuple(np.multiply(nose2, [100, 480]).astype(int)), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                            ) \n",
    "\n",
    "            cv2.rectangle(image1, (0,0), (265,63), (245,117,16), -1)\n",
    "\n",
    "#             # Rep data\n",
    "            cv2.putText(image1, 'CUMULATIVE SIMILARITY', (10,15),\n",
    "#             cv2.putText(image1, 'DIFFERANT', (10,15),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "            y = datetime.datetime.now().replace(microsecond=0)\n",
    "            z = y-x\n",
    "#             print(f'Datetime :{z} , Sim : [{round(compare_score_sim,4)}]')\n",
    "\n",
    "            # Stage data\n",
    "            cv2.putText(image1, 'SCORE', (200,15), \n",
    "#             cv2.putText(image1, 'SCORE', (100,15), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image1, 'Score', (120,50), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image1, str(z), (0,image1.shape[0]-5), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image1, results1.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                            mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=1), \n",
    "                                            mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=1) \n",
    "                                                )\n",
    "\n",
    "            mp_drawing.draw_landmarks(image2, results2.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                        mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=1), \n",
    "                                        mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=1) \n",
    "                                         )\n",
    "            #1\n",
    "            if diff_n > 9 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.NOSE.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.NOSE.value].y)*(image2.shape[0])))\n",
    "                           ,4,(0,0,255),-1)\n",
    "                worst_position += 1\n",
    "            #2\n",
    "            if diff_e_L > 35 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.LEFT_ELBOW.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.LEFT_ELBOW.value].y)*(image2.shape[0])))\n",
    "                           ,5,(0,0,255),-1)\n",
    "                worst_position += 1\n",
    "                \n",
    "            #3\n",
    "            if diff_e_R > 35 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y)*(image2.shape[0])))\n",
    "                           ,5,(0,0,255),-1)\n",
    "                worst_position += 1\n",
    "\n",
    "            #4\n",
    "            if diff_s_R > 26 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y)*(image2.shape[0])))\n",
    "                           ,5,(0,0,255),-1)\n",
    "                worst_position += 1\n",
    "            #5\n",
    "            if diff_s_L > 26 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y)*(image2.shape[0])))\n",
    "                           ,5,(0,0,255),-1)        \n",
    "                worst_position += 1\n",
    "            #6\n",
    "            if diff_h_L > 7 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.LEFT_HIP.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.LEFT_HIP.value].y)*(image2.shape[0])))\n",
    "                           ,5,(0,0,255),-1)  \n",
    "                worst_position += 1\n",
    "            #7\n",
    "            if diff_h_R > 7 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.RIGHT_HIP.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.RIGHT_HIP.value].y)*(image2.shape[0])))\n",
    "                           ,5,(0,0,255),-1)  \n",
    "                worst_position += 1\n",
    "            #8\n",
    "            if diff_k_L > 11 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.LEFT_KNEE.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.LEFT_KNEE.value].y)*(image2.shape[0])))\n",
    "                           ,5,(0,0,255),-1)\n",
    "                worst_position += 1\n",
    "            #9\n",
    "            if diff_k_R > 12 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.RIGHT_KNEE.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.RIGHT_KNEE.value].y)*(image2.shape[0])))\n",
    "                           ,5,(0,0,255),-1) \n",
    "                worst_position += 1\n",
    "                \n",
    "            percent_sim = ((9-worst_position)/9)*100\n",
    "            list_percent.append(percent_sim)\n",
    "            aver_percent = sum(list_percent)/len(list_percent)\n",
    "            cv2.putText(image1, str(round(aver_percent,2)), \n",
    "                        (10,50), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)        \n",
    "#             cv2.putText(image1, str(round(compare_score,2)), \n",
    "#                         (10,50), \n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "#             print(f'Datetime :{z} , Difference : [{round(compare_score,4)}]')\n",
    "            # to calculate FPS\n",
    "            currTime = time.time()\n",
    "            diff_sec = currTime - prevTime \n",
    "            fps = 1 / diff_sec\n",
    "            prevTime = currTime\n",
    "            cv2.putText(image2, f'FPS: {int(fps)}', (image2.shape[1]-80, image2.shape[0]-5), cv2.FONT_HERSHEY_PLAIN, 1, (0, 20, 255), 2)\n",
    "    #       cv2.putText(image1, f'FPS: {int(fps)}', (100, 220), cv2.FONT_HERSHEY_PLAIN, 1, (0, 20, 255), 2)\n",
    "\n",
    "            result = np.hstack((image1,image2))\n",
    "            cv2.imshow(\"Compare\", result)\n",
    "            frame_array.append(result)\n",
    "        \n",
    "        except:\n",
    "            pass        \n",
    "        \n",
    "        if worst_position >= 7 :\n",
    "            cv2.imwrite('./Improve your dance4/Not_corrent'+str(n)+'.jpg',result)\n",
    "            n += 1\n",
    "#         time.sleep(1/fps)\n",
    "        \n",
    "        # Wait 1 millisecond for any key press        \n",
    "        if (cv2.waitKey(1)== 27):       # press ESC to quit\n",
    "            break\n",
    "#         if val != 'eof' and audio_frame is not None:\n",
    "        #audio\n",
    "#             img, t = audio_frame\n",
    "    \n",
    "    # Recording Video\n",
    "    if mode == 'Y':\n",
    "        FPS = 9.0\n",
    "        size = (result.shape[1],result.shape[0])\n",
    "        video_output = 'improve_yourdance_Dif.mp4'\n",
    "        out = cv2.VideoWriter(video_output,cv2.VideoWriter_fourcc(*'FMP4'), FPS, size)\n",
    "        for i in range(len(frame_array)):\n",
    "            # writing to a image array\n",
    "            out.write(frame_array[i]) if mode == 'Y' else None\n",
    "        out.release()\n",
    "        \n",
    "#     print(f'Total Summary Similarity Score : {round(aver_percent,2)}')\n",
    "    # Calculate Std    \n",
    "#     print(diff_e_L_all)\n",
    "#     x1 = np.std(diff_n_all)\n",
    "#     x2 = np.std(diff_e_L_all)\n",
    "#     x3 = np.std(diff_e_R_all)\n",
    "#     x4 = np.std(diff_s_L_all)\n",
    "#     x5 = np.std(diff_s_R_all)\n",
    "#     x6 = np.std(diff_h_L_all)\n",
    "#     x7 = np.std(diff_h_R_all)\n",
    "#     x8 = np.std(diff_k_L_all)\n",
    "#     x9 = np.std(diff_k_R_all)\n",
    "#     x1m = stat.mean(diff_n_all)\n",
    "#     x2m = stat.mean(diff_e_L_all)\n",
    "#     x3m = stat.mean(diff_e_R_all)\n",
    "#     x4m = stat.mean(diff_s_L_all)\n",
    "#     x5m = stat.mean(diff_s_R_all)\n",
    "#     x6m = stat.mean(diff_h_L_all)\n",
    "#     x7m = stat.mean(diff_h_R_all)\n",
    "#     x8m = stat.mean(diff_k_L_all)\n",
    "#     x9m = stat.mean(diff_k_R_all)\n",
    "#     print(f'''\n",
    "#             SD Nose :{x1}, SD Left Elbow :{x2}, SD Right Elbow :{x3}, \n",
    "#             SD Left Shoulder :{x4},SD Right Shoulder :{x5},SD Left Hip :{x6},\n",
    "#             SD Right Hip :{x7},SD Left Knee :{x8},SD Right Knee :{x9}\n",
    "#             ''')\n",
    "#     print(f'''\n",
    "#             MEAN \n",
    "#             SD Nose :{x1m}, SD Left Elbow :{x2m}, SD Right Elbow :{x3m}, \n",
    "#             SD Left Shoulder :{x4m},SD Right Shoulder :{x5m},SD Left Hip :{x6m},\n",
    "#             SD Right Hip :{x7m},SD Left Knee :{x8m},SD Right Knee :{x9m}\n",
    "#             ''')\n",
    "#     y1 = np.std(diff_nose_y)\n",
    "#     print(f'[{x1}]') \n",
    "        \n",
    "#     print(s_nose1)\n",
    "#     print(s_elbow_L1)\n",
    "#     print(s_elbow_R1)\n",
    "#     print(s_shoulder_L1)\n",
    "#     print(s_shoulder_R1)\n",
    "#     print(s_hip_L1)\n",
    "#     print(s_hip_R1)\n",
    "#     print(s_knee_L1)\n",
    "#     print(s_knee_R1)\n",
    "    \n",
    "    cv2.destroyAllWindows() # close all windows\n",
    "    if bgv.isOpened():\n",
    "        bgv.release() \n",
    "    if hmv.isOpened():\n",
    "        hmv.release()\n",
    "        \n",
    "#     final1 = final.copy()\n",
    "#     final_frame = cv2.resize(final1, (768,864))\n",
    "#   final_frame = cv2.resize(final, (frame2.shape[0], frame2.shape[1]))\n",
    "#     cv2.imshow(\"Compare\", final1)\n",
    "#     time.sleep(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to record the result as a video? (Y/N): N\n"
     ]
    }
   ],
   "source": [
    "# Self-Camera\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "## Setup mediapipe instance\n",
    "\n",
    "bgv = cv2.VideoCapture(\"./lisa1.mp4\")\n",
    "# hmv = cv2.VideoCapture(\"./lisa2.mp4\")\n",
    "# bgv = cv2.VideoCapture(\"./2_green_dancing.mp4\")\n",
    "# hmv = cv2.VideoCapture(\"./2_green_dancing.mp4\")\n",
    "# hmv = cv2.VideoCapture(\"./Image video project/2.mp4\")\n",
    "# bgv = cv2.VideoCapture(\"./Image video project/3.mp4\")\n",
    "# final = cv2.imread(\"./Image video project/final_backgroup.jpg\")\n",
    "x = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "# video_path= \"./lisa2.mp4\"\n",
    "\n",
    "compare_collection = []\n",
    "compare_collection_sim = []\n",
    "\n",
    "s_nose1 = []\n",
    "s_elbow_L1 = []\n",
    "s_elbow_R1 = []\n",
    "s_shoulder_L1 = []\n",
    "s_shoulder_R1 = []\n",
    "s_hip_L1 = []\n",
    "s_hip_R1 = []\n",
    "s_knee_L1 = []\n",
    "s_knee_R1 = []\n",
    "\n",
    "diff_n_all = []\n",
    "diff_e_L_all = []\n",
    "diff_e_R_all = []\n",
    "diff_s_L_all = []\n",
    "diff_s_R_all = []\n",
    "diff_h_L_all = []\n",
    "diff_h_R_all = []   \n",
    "diff_k_L_all = []\n",
    "diff_k_R_all = []\n",
    "\n",
    "list_percent = []\n",
    "\n",
    "n = 1\n",
    "\n",
    "frame_array = []\n",
    "\n",
    "# if bgv.isOpened() and hmv.isOpened():\n",
    "#     print('Video file opened successfully.')\n",
    "# else:\n",
    "#     print('Error. Video file could not be opened.')\n",
    "\n",
    "# frames per second ==> lower it to slow down the video\n",
    "# fps = 1000\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "# to select mode (record or not)\n",
    "mode = input(\"Do you want to record the result as a video? (Y/N): \").upper()\n",
    "\n",
    "while mode not in ('Y', 'N'):\n",
    "    \n",
    "    print('Wrong input!')\n",
    "    mode = input(\"Do you want to record the result as a video? (Y/N): \").upper()\n",
    "\n",
    "# player = MediaPlayer(video_path)\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        ret1, bg1 = bgv.read()\n",
    "        ret2, hm2 = cap.read()\n",
    "#         audio_frame, val = player.get_frame()\n",
    "        \n",
    "        prevTime = time.time()\n",
    "        rt = 0.7\n",
    "        \n",
    "        if bg1 is None:\n",
    "#             768 ,432\n",
    "\n",
    "            break \n",
    "#     img1 = cv2.imread(\"./nida_background.jpg\")\n",
    "#     img = img1.copy()\n",
    "#     img = cv2.resize(img,(w,h))\n",
    "# cv2.rectangle(image1, (0,0), (265,63), (245,117,16), -1)\n",
    "\n",
    "#             # Rep data\n",
    "# cv2.putText(image1, 'CUMULATIVE SIMILARITY', (10,15), \n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "# y = datetime.datetime.now().replace(microsecond=0)\n",
    "# z = y-x\n",
    "# #           print(z)\n",
    "\n",
    "#             # Stage data\n",
    "# cv2.putText(image1, 'SCORE', (200,15), \n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            \n",
    "        whm = int(bg1.shape[1] *rt*1.3)\n",
    "        hhm = int(hm2.shape[0] *rt*1.2)\n",
    "    \n",
    "        frame1 = cv2.resize(bg1, (whm, hhm))\n",
    "        frame2 = cv2.resize(hm2, (whm, hhm))\n",
    "\n",
    "        # Recolor image to RGB\n",
    "        image1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "        image2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
    "        image1.flags.writeable = False\n",
    "        image2.flags.writeable = False\n",
    "\n",
    "        # Make detection\n",
    "        results1 = pose.process(image1)\n",
    "        results2 = pose.process(image2)\n",
    "\n",
    "        # Recolor back to BGR\n",
    "        image1.flags.writeable = True\n",
    "        image2.flags.writeable = True\n",
    "        image1 = cv2.cvtColor(image1, cv2.COLOR_RGB2BGR)\n",
    "        image2 = cv2.cvtColor(image2, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "        worst_position = 0\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks1 = results1.pose_world_landmarks.landmark\n",
    "            landmarks1_ = results1.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            nose1 = [landmarks1[mp_pose.PoseLandmark.NOSE.value].x,landmarks1[mp_pose.PoseLandmark.NOSE.value].y]\n",
    "            wrist_L1 = [landmarks1[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks1[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            wrist_R1 = [landmarks1[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks1[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            elbow_L1 = [landmarks1[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks1[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            elbow_R1 = [landmarks1[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks1[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            shoulder_L1 = [landmarks1[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks1[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            shoulder_R1 = [landmarks1[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks1[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            hip_L1 = [landmarks1[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks1[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            hip_R1 = [landmarks1[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks1[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            knee_L1 = [landmarks1[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks1[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            knee_R1 = [landmarks1[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks1[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            ankle_L1 = [landmarks1[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks1[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            ankle_R1 = [landmarks1[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks1[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]   \n",
    "\n",
    "\n",
    "            # Calculate angle\n",
    "            angle_nose1 = round(calculate_angle(shoulder_L1, nose1, shoulder_R1),2)\n",
    "            angle_elbow_L1 = round(calculate_angle(shoulder_L1, elbow_L1, wrist_L1),2)\n",
    "            angle_elbow_R1 = round(calculate_angle(shoulder_R1, elbow_R1, wrist_R1),2)\n",
    "            angle_shoulder_L1 = round(calculate_angle(elbow_L1, shoulder_L1, hip_L1),2)\n",
    "            angle_shoulder_R1 = round(calculate_angle(elbow_R1, shoulder_R1, hip_R1),2)\n",
    "            angle_hip_L1 = round(calculate_angle(shoulder_L1, hip_L1, knee_L1),2)\n",
    "            angle_hip_R1 = round(calculate_angle(shoulder_R1, hip_R1, knee_R1),2)            \n",
    "            angle_knee_L1 = round(calculate_angle(ankle_L1, knee_L1, hip_L1),2)\n",
    "            angle_knee_R1 = round(calculate_angle(ankle_R1, knee_R1, hip_R1),2)                       \n",
    "            \n",
    "            s_nose1.append(angle_nose1)\n",
    "            s_elbow_L1.append(angle_elbow_L1)\n",
    "            s_elbow_R1.append(angle_elbow_R1)\n",
    "            s_shoulder_L1.append(angle_shoulder_L1)\n",
    "            s_shoulder_R1.append(angle_shoulder_R1)\n",
    "            s_hip_L1.append(angle_hip_L1)\n",
    "            s_hip_R1.append(angle_hip_R1)\n",
    "            s_knee_L1.append(angle_knee_L1)\n",
    "            s_knee_R1.append(angle_knee_R1)      \n",
    "\n",
    "            landmarks2 = results2.pose_world_landmarks.landmark            \n",
    "            landmarks2_ = results2.pose_landmarks.landmark\n",
    "           \n",
    "            # Get coordinates\n",
    "            nose2 = [landmarks2[mp_pose.PoseLandmark.NOSE.value].x,landmarks2[mp_pose.PoseLandmark.NOSE.value].y]\n",
    "            wrist_L2 = [landmarks2[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks2[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            wrist_R2 = [landmarks2[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks2[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            elbow_L2 = [landmarks2[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks2[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            elbow_R2 = [landmarks2[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks2[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            shoulder_L2 = [landmarks2[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks2[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            shoulder_R2 = [landmarks2[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks2[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            hip_L2 = [landmarks2[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks2[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            hip_R2 = [landmarks2[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks2[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            knee_L2 = [landmarks2[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks2[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            knee_R2 = [landmarks2[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks2[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            ankle_L2 = [landmarks2[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks2[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            ankle_R2 = [landmarks2[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks2[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            \n",
    "            # Calculate angle\n",
    "            angle_nose2 = round(calculate_angle(shoulder_L2, nose2, shoulder_R2),2)\n",
    "            angle_elbow_L2 = round(calculate_angle(shoulder_L2, elbow_L2, wrist_L2),2)\n",
    "            angle_elbow_R2 = round(calculate_angle(shoulder_R2, elbow_R2, wrist_R2),2)\n",
    "            angle_shoulder_L2 = round(calculate_angle(elbow_L2, shoulder_L2, hip_L2),2)\n",
    "            angle_shoulder_R2 = round(calculate_angle(elbow_R2, shoulder_R2, hip_R2),2)\n",
    "            angle_hip_L2 = round(calculate_angle(shoulder_L2, hip_L2, knee_L2),2)\n",
    "            angle_hip_R2 = round(calculate_angle(shoulder_R2, hip_R2, knee_R2),2) \n",
    "            angle_knee_L2 = round(calculate_angle(ankle_L2, knee_L2, hip_L2),2)\n",
    "            angle_knee_R2 = round(calculate_angle(ankle_R2, knee_R2, hip_R2),2)\n",
    "            \n",
    "            compare_nose = abs(round(angle_nose2-angle_nose1,2))\n",
    "            compare_elbow_L = abs(round(angle_elbow_L2-angle_elbow_L1,2))\n",
    "            compare_elbow_R = abs(round(angle_elbow_R2-angle_elbow_R1,2))\n",
    "            compare_shoulder_L = abs(round(angle_shoulder_L2-angle_shoulder_L1,2)) \n",
    "            compare_shoulder_R = abs(round(angle_shoulder_R2-angle_shoulder_R1,2))            \n",
    "            compare_hip_L = abs(round(angle_hip_L2-angle_hip_L1,2)) \n",
    "            compare_hip_R = abs(round(angle_hip_R2-angle_hip_R1,2))\n",
    "            compare_knee_L = abs(round(angle_knee_L2-angle_knee_L1,2)) \n",
    "            compare_knee_R = abs(round(angle_knee_R2-angle_knee_R1,2)) \n",
    "            \n",
    "            compare_collection.append(compare_nose)\n",
    "            compare_collection.append(compare_elbow_L)\n",
    "            compare_collection.append(compare_elbow_R)    \n",
    "            compare_collection.append(compare_shoulder_L)\n",
    "            compare_collection.append(compare_shoulder_R)\n",
    "            compare_collection.append(compare_hip_L)\n",
    "            compare_collection.append(compare_hip_R)\n",
    "            compare_collection.append(compare_knee_L)\n",
    "            compare_collection.append(compare_knee_R)\n",
    "            \n",
    "            compare_score = sum(compare_collection)/len(compare_collection)\n",
    "            \n",
    "            # Calculate CosineSimilarity\n",
    "            cosinesim_nose = calculate_cosinesim(nose1,nose2)\n",
    "            cosinesim_elbow_L = calculate_cosinesim(elbow_L1,elbow_L2)\n",
    "            cosinesim_elbow_R = calculate_cosinesim(elbow_R1,elbow_R2)\n",
    "            cosinesim_shoulder_L = calculate_cosinesim(shoulder_L1,shoulder_L2)\n",
    "            cosinesim_shoulder_R = calculate_cosinesim(shoulder_R1,shoulder_R2)            \n",
    "            cosinesim_hip_L = calculate_cosinesim(hip_L1,hip_L2)\n",
    "            cosinesim_hip_R = calculate_cosinesim(hip_R1,hip_R2)\n",
    "            cosinesim_knee_L = calculate_cosinesim(knee_L1,knee_L2)\n",
    "            cosinesim_knee_R = calculate_cosinesim(knee_R1,knee_R2)\n",
    "            \n",
    "            compare_collection_sim.append(cosinesim_nose)\n",
    "            compare_collection_sim.append(cosinesim_elbow_L)\n",
    "            compare_collection_sim.append(cosinesim_elbow_R)    \n",
    "            compare_collection_sim.append(cosinesim_shoulder_L)\n",
    "            compare_collection_sim.append(cosinesim_shoulder_R)\n",
    "            compare_collection_sim.append(cosinesim_hip_L)\n",
    "            compare_collection_sim.append(cosinesim_hip_R)\n",
    "            compare_collection_sim.append(cosinesim_knee_L)\n",
    "            compare_collection_sim.append(cosinesim_knee_R)                       \n",
    "            \n",
    "            compare_score_sim = sum(compare_collection_sim)/len(compare_collection_sim)\n",
    "            \n",
    "            #Diff\n",
    "            diff_n = abs(angle_nose2 - angle_nose1)\n",
    "            diff_e_L = abs(angle_elbow_L2 - angle_elbow_L1)\n",
    "            diff_e_R = abs(angle_elbow_R2 - angle_elbow_R1)\n",
    "            diff_s_L = abs(angle_shoulder_L2 - angle_shoulder_L1)\n",
    "            diff_s_R = abs(angle_shoulder_R2 - angle_shoulder_R1)\n",
    "            diff_h_L = abs(angle_hip_L2 - angle_hip_L1)\n",
    "            diff_h_R = abs(angle_hip_R2 - angle_hip_R1)    \n",
    "            diff_k_L = abs(angle_knee_L2 - angle_knee_L1)\n",
    "            diff_k_R = abs(angle_knee_R2 - angle_knee_R1)\n",
    "         \n",
    "            diff_n_all.append(diff_n)\n",
    "            diff_e_L_all.append(diff_e_L)\n",
    "            diff_e_R_all.append(diff_e_R)\n",
    "            diff_s_L_all.append(diff_s_L)\n",
    "            diff_s_R_all.append(diff_s_R)\n",
    "            diff_h_L_all.append(diff_h_L)\n",
    "            diff_h_R_all.append(diff_h_R)\n",
    "            diff_k_L_all.append(diff_k_L)\n",
    "            diff_k_R_all.append(diff_k_R)\n",
    "\n",
    "            # Visualize angle\n",
    "            cv2.putText(image1, str(angle_nose1), \n",
    "                            tuple(np.multiply(nose1, [100, 480]).astype(int)), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                            )\n",
    "            cv2.putText(image2, str(angle_nose2), \n",
    "                            tuple(np.multiply(nose2, [100, 480]).astype(int)), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                            ) \n",
    "\n",
    "            cv2.rectangle(image1, (0,0), (265,63), (245,117,16), -1)\n",
    "\n",
    "#             # Rep data\n",
    "            cv2.putText(image1, 'CUMULATIVE SIMILARITY', (10,15),\n",
    "#             cv2.putText(image1, 'DIFFERANT', (10,15),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "            y = datetime.datetime.now().replace(microsecond=0)\n",
    "            z = y-x\n",
    "#             print(f'Datetime :{z} , Sim : [{round(compare_score_sim,4)}]')\n",
    "\n",
    "            # Stage data\n",
    "            cv2.putText(image1, 'SCORE', (200,15), \n",
    "#             cv2.putText(image1, 'SCORE', (100,15), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image1, 'Score', (120,50), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image1, str(z), (0,image1.shape[0]-5), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image1, results1.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                            mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=1), \n",
    "                                            mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=1) \n",
    "                                                )\n",
    "\n",
    "            mp_drawing.draw_landmarks(image2, results2.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                        mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=1), \n",
    "                                        mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=1) \n",
    "                                         )\n",
    "            #1\n",
    "            if diff_n > 9 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.NOSE.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.NOSE.value].y)*(image2.shape[0])))\n",
    "                           ,4,(0,0,255),-1)\n",
    "                worst_position += 1\n",
    "            #2\n",
    "            if diff_e_L > 35 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.LEFT_ELBOW.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.LEFT_ELBOW.value].y)*(image2.shape[0])))\n",
    "                           ,5,(0,0,255),-1)\n",
    "                worst_position += 1\n",
    "                \n",
    "            #3\n",
    "            if diff_e_R > 35 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y)*(image2.shape[0])))\n",
    "                           ,5,(0,0,255),-1)\n",
    "                worst_position += 1\n",
    "\n",
    "            #4\n",
    "            if diff_s_R > 26 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y)*(image2.shape[0])))\n",
    "                           ,5,(0,0,255),-1)\n",
    "                worst_position += 1\n",
    "            #5\n",
    "            if diff_s_L > 26 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y)*(image2.shape[0])))\n",
    "                           ,5,(0,0,255),-1)        \n",
    "                worst_position += 1\n",
    "            #6\n",
    "            if diff_h_L > 7 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.LEFT_HIP.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.LEFT_HIP.value].y)*(image2.shape[0])))\n",
    "                           ,5,(0,0,255),-1)  \n",
    "                worst_position += 1\n",
    "            #7\n",
    "            if diff_h_R > 7 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.RIGHT_HIP.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.RIGHT_HIP.value].y)*(image2.shape[0])))\n",
    "                           ,5,(0,0,255),-1)  \n",
    "                worst_position += 1\n",
    "            #8\n",
    "            if diff_k_L > 11 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.LEFT_KNEE.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.LEFT_KNEE.value].y)*(image2.shape[0])))\n",
    "                           ,5,(0,0,255),-1)\n",
    "                worst_position += 1\n",
    "            #9\n",
    "            if diff_k_R > 12 :  \n",
    "\n",
    "                cv2.circle(image2,\n",
    "                           (int((landmarks2_[mp_pose.PoseLandmark.RIGHT_KNEE.value].x)*(image2.shape[1])),\n",
    "                            int((landmarks2_[mp_pose.PoseLandmark.RIGHT_KNEE.value].y)*(image2.shape[0])))\n",
    "                           ,5,(0,0,255),-1) \n",
    "                worst_position += 1\n",
    "                \n",
    "            percent_sim = ((9-worst_position)/9)*100\n",
    "            list_percent.append(percent_sim)\n",
    "            aver_percent = sum(list_percent)/len(list_percent)\n",
    "            cv2.putText(image1, str(round(aver_percent,2)), \n",
    "                        (10,50), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)        \n",
    "#             cv2.putText(image1, str(round(compare_score,2)), \n",
    "#                         (10,50), \n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "#             print(f'Datetime :{z} , Difference : [{round(compare_score,4)}]')\n",
    "            # to calculate FPS\n",
    "            currTime = time.time()\n",
    "            diff_sec = currTime - prevTime \n",
    "            fps = 1 / diff_sec\n",
    "            prevTime = currTime\n",
    "            cv2.putText(image2, f'FPS: {int(fps)}', (image2.shape[1]-80, image2.shape[0]-5), cv2.FONT_HERSHEY_PLAIN, 1, (0, 20, 255), 2)\n",
    "    #       cv2.putText(image1, f'FPS: {int(fps)}', (100, 220), cv2.FONT_HERSHEY_PLAIN, 1, (0, 20, 255), 2)\n",
    "\n",
    "            result = np.hstack((image1,image2))\n",
    "            cv2.imshow(\"Compare\", result)\n",
    "            frame_array.append(result)\n",
    "        \n",
    "        except:\n",
    "            pass        \n",
    "        \n",
    "        if worst_position >= 7 :\n",
    "            cv2.imwrite('./Improve your dance4/Not_corrent'+str(n)+'.jpg',result)\n",
    "            n += 1\n",
    "#         time.sleep(1/fps)\n",
    "        \n",
    "        # Wait 1 millisecond for any key press        \n",
    "        if (cv2.waitKey(1)== 27):       # press ESC to quit\n",
    "            break\n",
    "#         if val != 'eof' and audio_frame is not None:\n",
    "        #audio\n",
    "#             img, t = audio_frame\n",
    "    \n",
    "    # Recording Video\n",
    "    if mode == 'Y':\n",
    "        FPS = 9.0\n",
    "        size = (result.shape[1],result.shape[0])\n",
    "        video_output = 'improve_yourdance_Dif.mp4'\n",
    "        out = cv2.VideoWriter(video_output,cv2.VideoWriter_fourcc(*'FMP4'), FPS, size)\n",
    "        for i in range(len(frame_array)):\n",
    "            # writing to a image array\n",
    "            out.write(frame_array[i]) if mode == 'Y' else None\n",
    "        out.release()\n",
    "        \n",
    "#     print(f'Total Summary Similarity Score : {round(aver_percent,2)}')\n",
    "    # Calculate Std    \n",
    "#     print(diff_e_L_all)\n",
    "#     x1 = np.std(diff_n_all)\n",
    "#     x2 = np.std(diff_e_L_all)\n",
    "#     x3 = np.std(diff_e_R_all)\n",
    "#     x4 = np.std(diff_s_L_all)\n",
    "#     x5 = np.std(diff_s_R_all)\n",
    "#     x6 = np.std(diff_h_L_all)\n",
    "#     x7 = np.std(diff_h_R_all)\n",
    "#     x8 = np.std(diff_k_L_all)\n",
    "#     x9 = np.std(diff_k_R_all)\n",
    "#     x1m = stat.mean(diff_n_all)\n",
    "#     x2m = stat.mean(diff_e_L_all)\n",
    "#     x3m = stat.mean(diff_e_R_all)\n",
    "#     x4m = stat.mean(diff_s_L_all)\n",
    "#     x5m = stat.mean(diff_s_R_all)\n",
    "#     x6m = stat.mean(diff_h_L_all)\n",
    "#     x7m = stat.mean(diff_h_R_all)\n",
    "#     x8m = stat.mean(diff_k_L_all)\n",
    "#     x9m = stat.mean(diff_k_R_all)\n",
    "#     print(f'''\n",
    "#             SD Nose :{x1}, SD Left Elbow :{x2}, SD Right Elbow :{x3}, \n",
    "#             SD Left Shoulder :{x4},SD Right Shoulder :{x5},SD Left Hip :{x6},\n",
    "#             SD Right Hip :{x7},SD Left Knee :{x8},SD Right Knee :{x9}\n",
    "#             ''')\n",
    "#     print(f'''\n",
    "#             MEAN \n",
    "#             SD Nose :{x1m}, SD Left Elbow :{x2m}, SD Right Elbow :{x3m}, \n",
    "#             SD Left Shoulder :{x4m},SD Right Shoulder :{x5m},SD Left Hip :{x6m},\n",
    "#             SD Right Hip :{x7m},SD Left Knee :{x8m},SD Right Knee :{x9m}\n",
    "#             ''')\n",
    "#     y1 = np.std(diff_nose_y)\n",
    "#     print(f'[{x1}]') \n",
    "        \n",
    "#     print(s_nose1)\n",
    "#     print(s_elbow_L1)\n",
    "#     print(s_elbow_R1)\n",
    "#     print(s_shoulder_L1)\n",
    "#     print(s_shoulder_R1)\n",
    "#     print(s_hip_L1)\n",
    "#     print(s_hip_R1)\n",
    "#     print(s_knee_L1)\n",
    "#     print(s_knee_R1)\n",
    "    \n",
    "    cv2.destroyAllWindows() # close all windows\n",
    "    if bgv.isOpened():\n",
    "        bgv.release() \n",
    "    if cap.isOpened():\n",
    "        cap.release()\n",
    "        \n",
    "#     final1 = final.copy()\n",
    "#     final_frame = cv2.resize(final1, (768,864))\n",
    "#   final_frame = cv2.resize(final, (frame2.shape[0], frame2.shape[1]))\n",
    "#     cv2.imshow(\"Compare\", final1)\n",
    "#     time.sleep(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8\n",
    "# 6\n",
    "# Summary Similarity Score : 70.34\n",
    "\n",
    "#             SD Nose :10.712056212473163, SD Left Elbow :32.403843263522376, SD Right Elbow :31.926708901826846, \n",
    "#             SD Left Shoulder :29.504158993738304,SD Right Shoulder :27.850519963379988,SD Left Hip :12.068899496580826,\n",
    "#             SD Right Hip :9.41515420478953,SD Left Knee :24.856498225468577,SD Right Knee :16.937783773885567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lisa1\n",
    "# lisa2\n",
    "#             Summary Similarity Score : 71.09\n",
    "#             SD Nose :9.442762395345369, SD Left Elbow :34.71705959601815, SD Right Elbow :35.158366172005245, \n",
    "#             SD Left Shoulder :23.61249989585603,SD Right Shoulder :23.209908874915335,SD Left Hip :9.602408793585118,\n",
    "#             SD Right Hip :5.815131287385943,SD Left Knee :13.893874785831313,SD Right Knee :15.293198207086116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lisa1\n",
    "# 10\n",
    "#             Summary Similarity Score : 69.97\n",
    "#             SD Nose :9.833876355267892, SD Left Elbow :32.032284629866915, SD Right Elbow :33.96477134058909, \n",
    "#             SD Left Shoulder :26.389510524864267,SD Right Shoulder :32.38056067909094,SD Left Hip :10.441435376836932,\n",
    "#             SD Right Hip :9.053553526357101,SD Left Knee :14.210427095733678,SD Right Knee :15.683968439378843"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lisa1\n",
    "#11\n",
    "#             Summary Similarity Score : 74.29\n",
    "#             SD Nose :9.391326870411179, SD Left Elbow :45.1791649951421, SD Right Elbow :38.55389129866383, \n",
    "#             SD Left Shoulder :26.081596355615435,SD Right Shoulder :24.79165916265061,SD Left Hip :5.668945213796037,\n",
    "#             SD Right Hip :4.812410512317276,SD Left Knee :9.478568509687532,SD Right Knee :13.359750618978637\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------ Code Backup ------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "vdo = cv2.VideoCapture(\"./Lisa1.mp4\")\n",
    "\n",
    "if vdo.isOpened():\n",
    "    print('Video file opened successfully.')\n",
    "else:\n",
    "    print('Error. Video file could not be opened.')\n",
    "    \n",
    "# frames per second ==> lower it to slow down the video\n",
    "# fps = 10000\n",
    "\n",
    "while vdo.isOpened():\n",
    "    \n",
    "    prevTime = time.time()\n",
    "    ret, img = vdo.read()\n",
    "    if not ret:\n",
    "        print(\"Error, no image from video file\")\n",
    "        break\n",
    "    \n",
    "    rt = 0.65 # percent of original size\n",
    "    w = int(img.shape[1] * rt)\n",
    "    h = int(img.shape[0] * rt)\n",
    "    img = cv2.resize(img, (w, h))\n",
    "    \n",
    "    img1 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img2 = cv2.applyColorMap(img, cv2.COLORMAP_WINTER)\n",
    "    img3 = img.copy()\n",
    "    \n",
    "    kernel = np.array([[-2, -2, -2],\n",
    "                       [0, 0, 0],\n",
    "                       [1, 1, 1]], dtype=np.float32)\n",
    "    kernel = cv2.flip(kernel, flipCode=-1)\n",
    "    top = bottom = kernel.shape[0] // 2\n",
    "    left = right = kernel.shape[1] // 2\n",
    "    src_pad = cv2.copyMakeBorder(img.copy(),\n",
    "                                 top, bottom, left, right,\n",
    "                                 cv2.BORDER_CONSTANT, value=0)\n",
    "    dst = cv2.filter2D(src_pad, -1, kernel)\n",
    "    img4 = dst[top:dst.shape[0]-bottom, left:dst.shape[1]-right]\n",
    "    \n",
    "    img5 = cv2.medianBlur(img, 7) \n",
    "    \n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh1 = 100\n",
    "    thresh2 = 150\n",
    "    canny = cv2.Canny(gray_img, thresh1, thresh2)\n",
    "    img6 = cv2.cvtColor(canny, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    result1 = np.hstack((img1, img2, img3))\n",
    "    result2 = np.hstack((img4, img5, img6))\n",
    "    result = np.vstack((result1, result2))\n",
    "    \n",
    "    # to calculate FPS\n",
    "    currTime = time.time()\n",
    "    diff_sec = currTime - prevTime \n",
    "    try :\n",
    "    \n",
    "        fps = 1 / diff_sec\n",
    "        prevTime = currTime\n",
    "        cv2.putText(result1, f'FPS: {int(fps)}', (65, 15), cv2.FONT_HERSHEY_PLAIN, 1, (0, 20, 255), 2)\n",
    "    except :\n",
    "        pass\n",
    "    cv2.imshow(\"1_Shiba\", result)\n",
    "    \n",
    "    # time.sleep(1/fps)\n",
    "    \n",
    "    # Wait 1 millisecond for any key press        \n",
    "    if (cv2.waitKey(1)== 27):       # press ESC to quit\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows() # close all windows\n",
    "if vdo.isOpened():\n",
    "    vdo.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  2  ( Code .)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgv = cv2.VideoCapture(\"./2_green_dancing.mp4\")\n",
    "hmv = cv2.VideoCapture(\"./2_green_dancing.mp4\")\n",
    "\n",
    "if bgv.isOpened() and hmv.isOpened() :\n",
    "    print('Video file opened successfully.')\n",
    "else:\n",
    "    print('Error. Video file could not be opened.')\n",
    "\n",
    "# frames per second ==> lower it to slow down the video\n",
    "# fps = 10000\n",
    "while True :\n",
    "    ret1, frame1 = bgv.read()\n",
    "    ret2, frame2 = hmv.read()\n",
    "\n",
    "    # time.sleep(1/fps)\n",
    "    rt = 0.7 # percent of original size\n",
    "#     w = int(frame1.shape[1] * rt)\n",
    "#     h = int(frame1.shape[0] * rt)\n",
    "    whm = int(frame1.shape[1] * rt * 0.75)\n",
    "    hhm = int(frame1.shape[0] * rt * 0.75)\n",
    "    bg = cv2.resize(frame1, (whm, hhm))\n",
    "    hm = cv2.resize(frame2, (whm, hhm))\n",
    "    \n",
    "    result = np.hstack((bg,hm))\n",
    "\n",
    "    cv2.imshow(\"1_Shiba\", result)\n",
    "    # time.sleep(1/fps)\n",
    "\n",
    "    # Wait 1 millisecond for any key press        \n",
    "    if (cv2.waitKey(1)== 27):       # press ESC to quit\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows() # close all windows\n",
    "if bgv.isOpened():\n",
    "        bgv.release() \n",
    "if hmv.isOpened():\n",
    "        hmv.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Human Pose Estimation ( 1 video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  HPE (Media pose  +  Angle )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "bgv = cv2.VideoCapture(\"./2_green_dancing.mp4\")\n",
    "\n",
    "if bgv.isOpened() :\n",
    "    print('Video file opened successfully.')\n",
    "else:\n",
    "    print('Error. Video file could not be opened.')\n",
    "\n",
    "# frames per second ==> lower it to slow down the video\n",
    "# fps = 10000\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    \n",
    "    while True:\n",
    "        ret1, frame = bgv.read()\n",
    "        print(frame.shape)\n",
    "        # print(bg.shape, hm.shape, de.shape)  \n",
    "\n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            # Calculate angle\n",
    "            angle = calculate_angle(shoulder, elbow, wrist)\n",
    "            \n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(angle), \n",
    "                           tuple(np.multiply(elbow, [640, 480]).astype(int)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "                       \n",
    "        except:\n",
    "            pass\n",
    "        cv2.circle(image,(100,100),4,(0,0,255),2)\n",
    "        \n",
    "        cv2.circle(image,(int((landmarks[mp_pose.PoseLandmark.NOSE.value].x)*(frame.shape[0])),int((landmarks[mp_pose.PoseLandmark.NOSE.value].y)*(frame.shape[1]))),4,(0,0,255),2)\n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, [landmarks[mp_pose.PoseLandmark.NOSE.value].x,landmarks[mp_pose.PoseLandmark.NOSE.value].y], mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        # time.sleep(1/fps)\n",
    "\n",
    "    #     result = np.hstack((bg2,hm2))\n",
    "\n",
    "        cv2.imshow(\"1_Shiba\", image)\n",
    "        # time.sleep(1/fps)\n",
    "\n",
    "        # Wait 1 millisecond for any key press        \n",
    "        if (cv2.waitKey(1)== 27):       # press ESC to quit\n",
    "            break\n",
    "            \n",
    "\n",
    "    cv2.destroyAllWindows() # close all windows\n",
    "    if bgv.isOpened():\n",
    "        bgv.release() \n",
    "    # if hmv.isOpened():\n",
    "    #     hmv.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Human Pose Comparison (2 Video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "bgv = cv2.VideoCapture(\"./2_green_dancing.mp4\")\n",
    "hmv = cv2.VideoCapture(\"./2_green_dancing.mp4\")\n",
    "# hmv = cv2.VideoCapture(\"./1_shiba.mp4\")\n",
    "\n",
    "if bgv.isOpened() and hmv.isOpened():\n",
    "    print('Video file opened successfully.')\n",
    "else:\n",
    "    print('Error. Video file could not be opened.')\n",
    "\n",
    "# frames per second ==> lower it to slow down the video\n",
    "# fps = 10000\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    \n",
    "    while True:\n",
    "        ret1, bg1 = bgv.read()\n",
    "        ret2, hm2 = hmv.read()\n",
    "        \n",
    "#         print(ret1)\n",
    "#         if bg1[0,0,0]>16 :\n",
    "#             pass\n",
    "#         else :\n",
    "#             break\n",
    "        \n",
    "        whm = int(bg1.shape[1] *rt*0.9)\n",
    "        hhm = int(hm2.shape[0] *rt* 0.9)\n",
    "        frame1 = cv2.resize(bg1, (whm, hhm))\n",
    "        frame2 = cv2.resize(hm2, (whm, hhm))\n",
    "\n",
    "        # Recolor image to RGB\n",
    "        image1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "        image2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
    "        image1.flags.writeable = False\n",
    "        image2.flags.writeable = False\n",
    "\n",
    "        # Make detection\n",
    "        results1 = pose.process(image1)\n",
    "        results2 = pose.process(image2)\n",
    "\n",
    "        # Recolor back to BGR\n",
    "        image1.flags.writeable = True\n",
    "        image2.flags.writeable = True\n",
    "        image1 = cv2.cvtColor(image1, cv2.COLOR_RGB2BGR)\n",
    "        image2 = cv2.cvtColor(image2, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks1 = results1.pose_landmarks.landmark\n",
    "        \n",
    "            # Get coordinates\n",
    "            shoulder1 = [landmarks1[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks1[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow1 = [landmarks1[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks1[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist1 = [landmarks1[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks1[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "\n",
    "            # Calculate angle\n",
    "            angle1 = calculate_angle(shoulder1, elbow1, wrist1)\n",
    "#             print(landmarks1)\n",
    "        \n",
    "        \n",
    "            landmarks2 = results2.pose_landmarks.landmark\n",
    "#             print(landmarks2)\n",
    "            # Get coordinates\n",
    "            shoulder2 = [landmarks2[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks2[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow2 = [landmarks2[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks2[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist2 = [landmarks2[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks2[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "\n",
    "            # Calculate angle\n",
    "            angle2 = calculate_angle(shoulder2, elbow2, wrist2)\n",
    "            print(angle2-angle1)\n",
    "\n",
    "            # Visualize angle\n",
    "            cv2.putText(image1, str(angle1), \n",
    "                        tuple(np.multiply(elbow1, [100, 480]).astype(int)), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                        )\n",
    "            cv2.putText(image2, str(angle2), \n",
    "                        tuple(np.multiply(elbow2, [640, 100]).astype(int)), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                        )                       \n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image1, results1.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                    )\n",
    "\n",
    "        mp_drawing.draw_landmarks(image2, results2.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                    )  \n",
    "  \n",
    "        result = np.hstack((image1,image2))\n",
    "        cv2.imshow(\"1_Shiba\", result)\n",
    "#         time.sleep(1/fps)\n",
    "        \n",
    "        # Wait 1 millisecond for any key press        \n",
    "        if (cv2.waitKey(1)== 27):       # press ESC to quit\n",
    "            break\n",
    "        \n",
    "    cv2.destroyAllWindows() # close all windows\n",
    "    if bgv.isOpened():\n",
    "        bgv.release() \n",
    "#     if hmv.isOpened():\n",
    "#         hmv.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "hmv = cv2.VideoCapture(\"./Lisa2.mp4\")\n",
    "## Setup mediapipe instance\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    \n",
    "    while True :\n",
    "        \n",
    "        ret, frame = hmv.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            print(landmarks)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lndmrk in mp_pose.PoseLandmark:\n",
    "    \n",
    "    print(lndmrk.value,lndmrk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose.PoseLandmark.LEFT_ELBOW.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findCosineSimilarity_1([3,3],[5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Angle\n",
    "## 2. Cosine Similarity\n",
    "## 3. -Point to Point- (Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.Openpose\n",
    "2.Blazepose\n",
    "3.HRnet\n",
    "4.Liftpose\n",
    "\n",
    "\n",
    "\n",
    "#1. Normalization\n",
    "2. Cosines Similarity Okey\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1.  + 5  cover Wait!!\n",
    "2.    (9 )  Threshold\n",
    "3.  cover video  4  Threshold  capture   Timestamp  save picture \n",
    "4. Save Video  \n",
    "5.  app"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
